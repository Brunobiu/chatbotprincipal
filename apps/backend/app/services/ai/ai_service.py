"""
Service para processar mensagens com IA (RAG + LLM)
"""
import logging
from typing import Dict, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from app.core.config import settings
from app.services.rag.vectorstore import buscar_no_vectorstore
from app.services.conversations.memory import get_session_history
from app.db.models.ia_configuracao import IAConfiguracao

logger = logging.getLogger(__name__)


class AIService:
    """Service para processar mensagens com IA"""
    
    @staticmethod
    def processar_mensagem(
        cliente_id: int,
        chat_id: str,
        mensagem: str,
        tom: str = "casual",
        nome_empresa: str = None,
        primeira_mensagem: bool = False,
        nome_usuario: str = None
    ) -> Dict:
        """
        Processa mensagem do usu√°rio e gera resposta com IA
        
        Args:
            cliente_id: ID do cliente
            chat_id: ID do chat (session_id)
            mensagem: Mensagem do usu√°rio
            tom: Tom das respostas (formal, casual, tecnico)
            nome_empresa: Nome da empresa para sauda√ß√£o
            primeira_mensagem: Se √© a primeira mensagem da conversa
            nome_usuario: Nome do usu√°rio (se conhecido)
            
        Returns:
            Dict com 'resposta', 'contexto_usado', 'confianca'
        """
        logger.info(f"Processando mensagem para cliente {cliente_id}: '{mensagem[:50]}...'")
        
        # 1. Buscar contexto no vectorstore (RAG)
        contexto_docs = buscar_no_vectorstore(cliente_id, mensagem, k=5)
        
        if not contexto_docs or len(contexto_docs) == 0:
            logger.warning(f"Nenhum embedding encontrado para cliente {cliente_id} - usando conhecimento estruturado")
            
            # Fallback: buscar conhecimento direto do banco
            from app.db.session import SessionLocal
            from app.services.conhecimento import ConhecimentoService
            from app.services.conhecimento.estruturador_service import EstruturadorService
            
            db = SessionLocal()
            try:
                conhecimento = ConhecimentoService.buscar_ou_criar(db, cliente_id)
                
                # Priorizar JSON estruturado se existir
                if conhecimento.conteudo_estruturado:
                    logger.info(f"‚úÖ Usando conhecimento estruturado (JSON)")
                    contexto_texto = EstruturadorService.json_para_texto_busca(conhecimento.conteudo_estruturado)
                    confianca = 0.7  # Confian√ßa alta quando usa JSON estruturado
                elif conhecimento.conteudo_texto and len(conhecimento.conteudo_texto.strip()) > 0:
                    logger.info(f"‚ö†Ô∏è Usando texto direto (JSON n√£o dispon√≠vel)")
                    contexto_texto = conhecimento.conteudo_texto
                    confianca = 0.5  # Confian√ßa m√©dia quando usa texto direto
                else:
                    contexto_texto = "Nenhum conhecimento dispon√≠vel."
                    confianca = 0.0
                    
                logger.info(f"Usando conhecimento: {len(contexto_texto)} chars, confian√ßa: {confianca}")
            finally:
                db.close()
        else:
            # Montar texto do contexto
            contexto_texto = "\n\n".join([
                f"[Trecho {i+1}]: {doc['text']}"
                for i, doc in enumerate(contexto_docs)
            ])
            
            # Calcular confian√ßa m√©dia baseada nos scores
            scores = [doc['score'] for doc in contexto_docs]
            confianca = 1.0 - (sum(scores) / len(scores))  # Inverter score (menor = melhor)
            
            logger.info(f"Contexto encontrado: {len(contexto_docs)} chunks, confian√ßa: {confianca:.2f}")
        
        # 2. Buscar hist√≥rico da conversa (√∫ltimas 10 mensagens)
        session_history = get_session_history(chat_id)
        historico_mensagens = session_history.messages[-10:] if session_history.messages else []
        
        logger.info(f"Hist√≥rico: {len(historico_mensagens)} mensagens")
        
        # 3. Montar prompt baseado no tom
        system_prompt = AIService._get_system_prompt(tom, contexto_texto, nome_empresa, nome_usuario)
        
        # 4. Montar mensagens para o LLM
        messages = [SystemMessage(content=system_prompt)]
        
        # Adicionar hist√≥rico
        for msg in historico_mensagens:
            messages.append(msg)
        
        # Adicionar mensagem atual
        messages.append(HumanMessage(content=mensagem))
        
        # 5. Chamar IA com fallback autom√°tico
        try:
            from app.db.session import SessionLocal
            from app.services.ia_config_service import IAConfigService
            
            # Buscar TODOS os provedores configurados (ordenados por prioridade)
            db_config = SessionLocal()
            try:
                # Buscar provedor ativo
                config_ativa = IAConfigService.get_api_key_ativa(db_config)
                
                # Buscar todos configurados como backup
                todos_configs = db_config.query(IAConfiguracao).filter_by(configurado=True).all()
                
                # Ordenar: ativo primeiro, depois os outros
                configs_ordenadas = []
                if config_ativa:
                    configs_ordenadas.append(config_ativa)
                
                for cfg in todos_configs:
                    provedor_cfg = (cfg.provedor, cfg.modelo, IAConfigService.decrypt_key(cfg.api_key_encrypted))
                    if config_ativa and cfg.provedor == config_ativa[0]:
                        continue  # J√° adicionou
                    configs_ordenadas.append(provedor_cfg)
                
            finally:
                db_config.close()
            
            # Tentar cada provedor at√© funcionar
            ultima_exception = None
            
            for idx, config in enumerate(configs_ordenadas):
                provedor, modelo, api_key = config
                
                try:
                    if idx == 0:
                        logger.info(f"ü§ñ Tentando {provedor} ({modelo}) - Provedor ativo")
                    else:
                        logger.warning(f"üîÑ Fallback: Tentando {provedor} ({modelo})")
                    
                    # Usar provedor
                    if provedor == 'openai':
                        llm = ChatOpenAI(
                            model=modelo,
                            temperature=float(settings.OPENAI_MODEL_TEMPERATURE),
                            openai_api_key=api_key
                        )
                    else:
                        # Outros provedores ainda n√£o implementados
                        continue
                    
                    # Tentar gerar resposta
                    response = llm.invoke(messages)
                    resposta = response.content
                    
                    # ‚úÖ Sucesso! Sair do loop
                    if idx > 0:
                        logger.info(f"‚úÖ Fallback bem-sucedido! Usando {provedor}")
                    break
                    
                except Exception as e:
                    ultima_exception = e
                    error_msg = str(e).lower()
                    
                    # Detectar erros de limite/quota
                    if any(x in error_msg for x in ['rate limit', 'quota', 'insufficient', 'exceeded']):
                        logger.error(f"‚ùå {provedor} atingiu limite: {e}")
                        # Tentar pr√≥ximo
                        continue
                    else:
                        # Outro tipo de erro, tentar pr√≥ximo tamb√©m
                        logger.error(f"‚ùå Erro em {provedor}: {e}")
                        continue
            
            # Se nenhum funcionou, tentar .env como √∫ltimo recurso
            if 'resposta' not in locals():
                logger.warning(f"‚ö†Ô∏è Todos os provedores falharam, tentando .env como √∫ltimo recurso")
                try:
                    llm = ChatOpenAI(
                        model=settings.OPENAI_MODEL_NAME,
                        temperature=float(settings.OPENAI_MODEL_TEMPERATURE)
                    )
                    response = llm.invoke(messages)
                    resposta = response.content
                    logger.info(f"‚úÖ Fallback .env bem-sucedido!")
                except Exception as e:
                    logger.error(f"‚ùå At√© o .env falhou: {e}")
                    raise ultima_exception or e
            
            # üìä REGISTRAR USO DA OPENAI (FASE 16.4)
            try:
                from app.db.session import SessionLocal
                from app.services.uso import UsoOpenAIService
                
                # Extrair tokens da resposta
                tokens_prompt = response.response_metadata.get('token_usage', {}).get('prompt_tokens', 0)
                tokens_completion = response.response_metadata.get('token_usage', {}).get('completion_tokens', 0)
                
                if tokens_prompt > 0 or tokens_completion > 0:
                    db = SessionLocal()
                    try:
                        UsoOpenAIService.registrar_uso(
                            db=db,
                            cliente_id=cliente_id,
                            modelo=settings.OPENAI_MODEL_NAME,
                            tokens_prompt=tokens_prompt,
                            tokens_completion=tokens_completion
                        )
                    finally:
                        db.close()
            except Exception as e:
                logger.error(f"Erro ao registrar uso OpenAI: {e}")
                # N√£o falhar a requisi√ß√£o por erro no registro
            
            # 6. Adicionar sauda√ß√£o se for primeira mensagem
            if primeira_mensagem:
                from datetime import datetime
                hora = datetime.now().hour
                
                if 5 <= hora < 12:
                    saudacao = "Bom dia"
                elif 12 <= hora < 18:
                    saudacao = "Boa tarde"
                else:
                    saudacao = "Boa noite"
                
                # Sauda√ß√£o simples sem nome da empresa
                resposta = f"{saudacao}! Como posso ajudar voc√™?\n\n{resposta}"
            
            logger.info(f"Resposta gerada: '{resposta[:50]}...'")
            
            # 7. Salvar no hist√≥rico
            session_history.add_user_message(mensagem)
            session_history.add_ai_message(resposta)
            
            return {
                "resposta": resposta,
                "contexto_usado": len(contexto_docs),
                "confianca": confianca,
                "documentos": contexto_docs  # Adicionar documentos para c√°lculo de confian√ßa
            }
            
        except Exception as e:
            logger.error(f"Erro ao gerar resposta: {e}")
            raise
    
    @staticmethod
    def _get_system_prompt(tom: str, contexto: str, nome_empresa: str = None, nome_usuario: str = None) -> str:
        """
        Gera system prompt baseado no tom e contexto
        """
        tom_instrucoes = {
            "formal": "Voc√™ deve ser profissional, respeitoso e usar linguagem formal.",
            "casual": "Voc√™ deve ser amig√°vel, descontra√≠do e usar linguagem casual.",
            "tecnico": "Voc√™ deve ser preciso, t√©cnico e usar terminologia especializada."
        }
        
        instrucao_tom = tom_instrucoes.get(tom, tom_instrucoes["casual"])
        
        # Adicionar instru√ß√£o sobre uso do nome
        instrucao_nome = ""
        if nome_usuario:
            instrucao_nome = f"\n\nIMPORTANTE: O nome do usu√°rio √© {nome_usuario}. Use o nome dele nas respostas de forma natural e amig√°vel."
        
        return f"""Voc√™ √© um assistente virtual de atendimento. {instrucao_tom}{instrucao_nome}

REGRAS IMPORTANTES:

1. TOLER√ÇNCIA COM ERROS:
   - Seja tolerante com erros de digita√ß√£o (ex: "queor" = "quero", "cachoro" = "cachorro")
   - Tente entender a INTEN√á√ÉO da mensagem, n√£o apenas as palavras exatas
   - Se entender a inten√ß√£o, responda normalmente

2. SAUDA√á√ïES E MENSAGENS GERAIS:
   - Se a pessoa apenas cumprimentar (oi, ol√°, bom dia, boa tarde, e a√≠, etc), responda de forma amig√°vel e pergunte como pode ajudar
   - Exemplo: "Ol√°{', ' + nome_usuario if nome_usuario else ''}! Como posso ajudar voc√™ hoje?"
   - Seja natural e receptivo

3. PERGUNTAS ESPEC√çFICAS:
   - Para perguntas sobre produtos/servi√ßos, responda APENAS com base no conhecimento abaixo
   - Se voc√™ REALMENTE n√£o souber ou a informa√ß√£o n√£o estiver no conhecimento, responda EXATAMENTE: "N√£o tenho essa informa√ß√£o no momento."
   - IMPORTANTE: Use essa frase exata para que possamos transferir para um atendente humano
   
4. PERGUNTAS FORA DO ESCOPO:
   - Para perguntas n√£o relacionadas ao neg√≥cio (hora, tempo, not√≠cias, etc), responda: "Desculpe, s√≥ posso ajudar com informa√ß√µes sobre nossos servi√ßos."

5. ESTILO:
   - Seja conciso (m√°ximo 3 frases)
   - Seja amig√°vel e prestativo
   - N√£o invente informa√ß√µes

CONHECIMENTO DISPON√çVEL:
{contexto}

Responda de forma natural e √∫til."""

    @staticmethod
    def melhorar_conhecimento(texto: str) -> str:
        """
        Usa IA para estruturar e melhorar texto do conhecimento
        
        Args:
            texto: Texto bruto do conhecimento
            
        Returns:
            Texto estruturado e melhorado
        """
        logger.info(f"ü§ñ Melhorando conhecimento com IA: {len(texto)} chars")
        
        try:
            llm = ChatOpenAI(
                model=settings.OPENAI_MODEL,
                temperature=0.3,  # Baixa temperatura para respostas mais consistentes
                api_key=settings.OPENAI_API_KEY
            )
            
            system_prompt = """Voc√™ √© um assistente especializado em estruturar e melhorar textos de conhecimento para chatbots.

Sua tarefa √©:
1. Organizar o texto em t√≥picos claros e bem estruturados
2. Corrigir erros de portugu√™s
3. Melhorar a clareza e objetividade
4. Adicionar formata√ß√£o com marcadores e subt√≠tulos quando apropriado
5. Manter TODAS as informa√ß√µes importantes do texto original
6. N√ÉO inventar informa√ß√µes que n√£o est√£o no texto original

Formato de sa√≠da:
- Use t√≠tulos em MAI√öSCULAS para se√ß√µes principais
- Use marcadores (‚Ä¢) para listas
- Seja conciso mas completo
- Mantenha um tom profissional mas acess√≠vel

Exemplo de estrutura:

SOBRE A EMPRESA
‚Ä¢ Informa√ß√£o 1
‚Ä¢ Informa√ß√£o 2

PRODUTOS E SERVI√áOS
‚Ä¢ Produto 1: descri√ß√£o
‚Ä¢ Produto 2: descri√ß√£o

HOR√ÅRIOS E CONTATO
‚Ä¢ Hor√°rio: informa√ß√£o
‚Ä¢ Telefone: informa√ß√£o
‚Ä¢ Email: informa√ß√£o

POL√çTICAS
‚Ä¢ Pol√≠tica 1
‚Ä¢ Pol√≠tica 2"""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Melhore e estruture este texto:\n\n{texto}")
            ]
            
            response = llm.invoke(messages)
            texto_melhorado = response.content
            
            logger.info(f"‚úÖ Texto melhorado: {len(texto_melhorado)} chars")
            
            return texto_melhorado
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao melhorar conhecimento: {str(e)}", exc_info=True)
            raise
